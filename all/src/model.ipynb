{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D,Dense,Flatten,Concatenate,BatchNormalization,Input,Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = '../train.csv'\n",
    "TEST_FILE = '../test.csv'\n",
    "TOKENIZER = Tokenizer(num_words=10000)\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datify(text_file):\n",
    "    sentences=[]\n",
    "    sentiments=[]\n",
    "    maxlength =0\n",
    "    with open(text_file,errors='ignore') as f:\n",
    "        f.readline()\n",
    "        for line in f:\n",
    "            try:\n",
    "                _,sentiment,sentence = line.split(',')\n",
    "                sentences.append(sentence)\n",
    "                len_sent = len(sentence)\n",
    "                if(maxlength<len_sent):\n",
    "                    maxlength = len_sent\n",
    "                sentiments.append(sentiment)\n",
    "            except:\n",
    "                pass\n",
    "    TOKENIZER.fit_on_texts(sentences)\n",
    "    sentences = TOKENIZER.texts_to_sequences(sentences)\n",
    "    sentences = pad_sequences(sentences,maxlen = maxlength)\n",
    "    return sentences,sentiments,maxlength\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y,train_length = datify(TRAIN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer definition\n",
    "vocab_size = len(TOKENIZER.word_index)+1\n",
    "input1 = Input(shape=(train_length,))\n",
    "embedding1 = Embedding(vocab_size,100)(input1)\n",
    "layer1_group1_conv = Conv1D(filters=32,kernel_size=2,activation='relu')(embedding1)\n",
    "layer1_group1_bn = BatchNormalization()(layer1_group1_conv)\n",
    "layer1_group1_flat = Flatten()(layer1_group1_bn)\n",
    "input2 = Input(shape=(train_length,))\n",
    "embedding2 = Embedding(vocab_size,100)(input2)\n",
    "layer1_group2_conv = Conv1D(filters=32,kernel_size=3,activation='relu')(embedding2)\n",
    "layer1_group2_bn = BatchNormalization()(layer1_group2_conv)\n",
    "layer1_group2_flat = Flatten()(layer1_group2_bn)\n",
    "input3 = Input(shape=(train_length,))\n",
    "embedding3 = Embedding(vocab_size,100)(input3)\n",
    "layer1_group3_conv = Conv1D(filters=32,kernel_size=4,activation='relu')(embedding3)\n",
    "layer1_group3_bn = BatchNormalization()(layer1_group3_conv)\n",
    "layer1_group3_flat = Flatten()(layer1_group3_bn)\n",
    "layer2_concat = Concatenate()([layer1_group1_flat,layer1_group2_flat,layer1_group3_flat])\n",
    "layer3_dense = Dense(10,activation='relu')(layer2_concat)\n",
    "layer4_out = Dense(1,activation='sigmoid')(layer3_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "model = Model(inputs=[input1,input2,input3],outputs=layer4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model,to_file='../images/model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75206/75206 [==============================] - 1324s 18ms/step - loss: 0.0882 - acc: 0.9654\n",
      "Epoch 2/3\n",
      "75206/75206 [==============================] - 1388s 18ms/step - loss: 0.0679 - acc: 0.9730\n",
      "Epoch 3/3\n",
      "75206/75206 [==============================] - 1276s 17ms/step - loss: 0.0603 - acc: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f803eddf9e8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_x,train_x,train_x],train_y,epochs=3,batch_size=32) #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "model.save('../model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f80410a1c50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfjs.converters.save_keras_model('../model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
